[{
    "model_name": ["gpt2"],
    "syn_exp_name": ["autoreg_ksteps"],
    "seed": [201],
    "num_attack_tokens": [1],
    "num_steps": [2],
    "embed_dim": [32],
    "num_layers": [1],
    "num_heads": [1],
    "min_chain_len": [4],
    "max_chain_len": [7],
    "min_num_rules": [32],
    "max_num_rules": [64],
    "num_vars": [16],
    "min_ante_prob": [0.2],
    "max_ante_prob": [0.3],
    "min_conseq_prob": [0.2],
    "max_conseq_prob": [0.3],
    "train_len": [65536],
    "eval_len": [32768],
    "num_epochs": [50],
    "train_batch_size": [1024],
    "eval_batch_size": [1024],
    "base_attack_model_name": ["gpt2"],
    "num_attack_epochs": [5],
    "attack_train_batch_size": [128],
    "attack_eval_batch_size": [128],
    "attack_train_len": [32768],
    "attack_eval_len": [16384],
    "clamp": [0]
},
{
    "model_name": ["gpt2"],
    "syn_exp_name": ["autoreg_ksteps"],
    "seed": [201],
    "num_attack_tokens": [1],
    "num_steps": [2],
    "embed_dim": [64],
    "num_layers": [1],
    "num_heads": [1],
    "min_chain_len": [4],
    "max_chain_len": [7],
    "min_num_rules": [32],
    "max_num_rules": [64],
    "num_vars": [16, 32],
    "min_ante_prob": [0.2],
    "max_ante_prob": [0.3],
    "min_conseq_prob": [0.2],
    "max_conseq_prob": [0.3],
    "train_len": [65536],
    "eval_len": [32768],
    "num_epochs": [50],
    "train_batch_size": [1024],
    "eval_batch_size": [1024],
    "base_attack_model_name": ["gpt2"],
    "num_attack_epochs": [5],
    "attack_train_batch_size": [128],
    "attack_eval_batch_size": [128],
    "attack_train_len": [32768],
    "attack_eval_len": [16384],
    "clamp": [0]
},
{
    "model_name": ["gpt2"],
    "syn_exp_name": ["autoreg_ksteps"],
    "seed": [201],
    "num_attack_tokens": [1],
    "num_steps": [1, 2],
    "embed_dim": [128],
    "num_layers": [1],
    "num_heads": [1],
    "min_chain_len": [4],
    "max_chain_len": [7],
    "min_num_rules": [32],
    "max_num_rules": [64],
    "num_vars": [16, 32, 48],
    "min_ante_prob": [0.2],
    "max_ante_prob": [0.3],
    "min_conseq_prob": [0.2],
    "max_conseq_prob": [0.3],
    "train_len": [65536],
    "eval_len": [32768],
    "num_epochs": [50],
    "train_batch_size": [1024],
    "eval_batch_size": [1024],
    "base_attack_model_name": ["gpt2"],
    "num_attack_epochs": [5],
    "attack_train_batch_size": [128],
    "attack_eval_batch_size": [128],
    "attack_train_len": [32768],
    "attack_eval_len": [16384],
    "clamp": [0]
}
]