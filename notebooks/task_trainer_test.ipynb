{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a10ed89-e454-4e4d-97d6-1a145e835ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import torch\n",
    "from torch.utils.data import *\n",
    "from transformers import *\n",
    "import inspect\n",
    "import sys\n",
    "sys.path.insert(0, \"..\")\n",
    "\n",
    "from models import *\n",
    "from logic import *\n",
    "from my_datasets import *\n",
    "\n",
    "from utils import *\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce046867-0d4c-47fd-9258-5c7d227eb388",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2227ffe-cb8b-4514-965d-609766d87643",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd59af34-9ef4-4d58-a75b-03d4b7e6335f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n, r = 5, 8\n",
    "ap, bp, tp = 0.2, 0.2, 0.4\n",
    "\n",
    "qed_train_dataset_config = OneShotQedDatasetConfig(r, n, ap, bp, tp, num_items=640, base_seed=1234)\n",
    "qed_test_dataset_config = OneShotQedDatasetConfig(r, n, ap, bp, tp, num_items=640, base_seed=2345)\n",
    "qed_train_dataset = OneShotQedDataset(qed_train_dataset_config)\n",
    "qed_test_dataset = OneShotQedDataset(qed_test_dataset_config)\n",
    "\n",
    "succ_train_dataset_config = PredictSuccDatasetConfig(r, n, ap, bp, tp, num_items=1000, base_seed=1234)\n",
    "succ_test_dataset_config = PredictSuccDatasetConfig(r, n, ap, bp, tp, num_items=500, base_seed=2345)\n",
    "succ_train_dataset = PredictSuccDataset(succ_train_dataset_config)\n",
    "succ_test_dataset = PredictSuccDataset(succ_test_dataset_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9bdceb-8b3d-46ca-8dd3-5372dc8fc0b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4cfeab7e-e7fd-408c-bd92-2614d3c9cfce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /home/antonxue/.cache/huggingface/hub/models--gpt2/snapshots/11c5a3d5811f50298f278a704980280950aedb10/config.json\n",
      "Model config GPT2Config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"reorder_and_upcast_attn\": false,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_by_inverse_layer_idx\": false,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.34.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "loading weights file model.safetensors from cache at /home/antonxue/.cache/huggingface/hub/models--gpt2/snapshots/11c5a3d5811f50298f278a704980280950aedb10/model.safetensors\n",
      "All model checkpoint weights were used when initializing GPT2Model.\n",
      "\n",
      "All the weights of GPT2Model were initialized from the model checkpoint at gpt2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2Model for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "mytf_config = MyTfConfig(embed_dim=768, ffwd_width=1024, ffwd_depth=4, num_heads=2, num_layers=8)\n",
    "mytf_model = get_seq2seq_model(\"mytf\", config=mytf_config)\n",
    "mytf_qed_model = OneShotQedTaskModel(OneShotQedTaskConfig(r, n, copy.deepcopy(mytf_model)))\n",
    "mytf_succ_model = PredictSuccTaskModel(PredictSuccTaskConfig(r, n, copy.deepcopy(mytf_model)))\n",
    "\n",
    "mygpt2_model = get_seq2seq_model(\"gpt2\", use_pretrained=True)\n",
    "mygpt2_qed_model = OneShotQedTaskModel(OneShotQedTaskConfig(r, n, copy.deepcopy(mygpt2_model)))\n",
    "mygpt2_succ_model = PredictSuccTaskModel(PredictSuccTaskConfig(r, n, copy.deepcopy(mygpt2_model)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b98a8e18-88c5-4c1a-971b-39a46a5ad6a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found safetensors installation, but --save_safetensors=False. Safetensors should be a preferred weights saving format due to security and performance reasons. If your model cannot be saved by safetensors please feel free to open an issue at https://github.com/huggingface/safetensors!\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "qed_training_args = TrainingArguments(\n",
    "    \"test-trainer\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    num_train_epochs = 100,\n",
    "    per_device_train_batch_size = 24,\n",
    "    per_device_eval_batch_size = 24,\n",
    "    logging_steps = 5\n",
    ")\n",
    "\n",
    "succ_training_args = qed_training_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6973e790-3dc9-430e-b620-8cc936fb5752",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### QED GPT2\n",
    "mygpt2_qed_trainer = Trainer(mygpt2_qed_model, qed_training_args,\n",
    "    train_dataset = qed_train_dataset,\n",
    "    eval_dataset = qed_test_dataset,\n",
    "    compute_metrics = qed_compute_metrics)\n",
    "# mygpt2_qed_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "087439c1-e512-4fdf-96c2-578aae85a7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "### QED MyTf\n",
    "mytf_qed_trainer = Trainer(mytf_qed_model, qed_training_args,\n",
    "    train_dataset = qed_train_dataset,\n",
    "    eval_dataset = qed_test_dataset,\n",
    "    compute_metrics = qed_compute_metrics)\n",
    "# mytf_qed_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9193d5ab-6de1-4158-822c-1206b629383b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1969a6-15fd-4941-9312-d60ebc8b9dbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 1,000\n",
      "  Num Epochs = 100\n",
      "  Instantaneous batch size per device = 24\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 24\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 4,200\n",
      "  Number of trainable parameters = 126,424,325\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3907' max='4200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3907/4200 10:31 < 00:47, 6.18 it/s, Epoch 93/100]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Avg ones</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.533100</td>\n",
       "      <td>0.538160</td>\n",
       "      <td>0.779200</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.547400</td>\n",
       "      <td>0.531928</td>\n",
       "      <td>0.779200</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.528100</td>\n",
       "      <td>0.540472</td>\n",
       "      <td>0.779200</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.523000</td>\n",
       "      <td>0.535523</td>\n",
       "      <td>0.779200</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.459200</td>\n",
       "      <td>0.562002</td>\n",
       "      <td>0.779200</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.444900</td>\n",
       "      <td>0.567684</td>\n",
       "      <td>0.779200</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.373100</td>\n",
       "      <td>0.550001</td>\n",
       "      <td>0.779200</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.325000</td>\n",
       "      <td>0.719572</td>\n",
       "      <td>0.779200</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.256400</td>\n",
       "      <td>0.817121</td>\n",
       "      <td>0.779200</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.297800</td>\n",
       "      <td>1.107274</td>\n",
       "      <td>0.779200</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.176600</td>\n",
       "      <td>1.245744</td>\n",
       "      <td>0.779200</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.090500</td>\n",
       "      <td>1.325143</td>\n",
       "      <td>0.566400</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.104100</td>\n",
       "      <td>1.484622</td>\n",
       "      <td>0.682400</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.121700</td>\n",
       "      <td>0.937791</td>\n",
       "      <td>0.663200</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.056000</td>\n",
       "      <td>1.608047</td>\n",
       "      <td>0.536800</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.090200</td>\n",
       "      <td>2.035453</td>\n",
       "      <td>0.536800</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.033400</td>\n",
       "      <td>1.811863</td>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.014800</td>\n",
       "      <td>1.463182</td>\n",
       "      <td>0.779200</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.013900</td>\n",
       "      <td>1.705347</td>\n",
       "      <td>0.656000</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.025800</td>\n",
       "      <td>1.783778</td>\n",
       "      <td>0.663200</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.016400</td>\n",
       "      <td>5.212228</td>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.003100</td>\n",
       "      <td>5.312618</td>\n",
       "      <td>0.779200</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>5.530915</td>\n",
       "      <td>0.656000</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>2.147890</td>\n",
       "      <td>0.779200</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>2.408249</td>\n",
       "      <td>0.779200</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>2.357039</td>\n",
       "      <td>0.779200</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>2.356028</td>\n",
       "      <td>0.779200</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>5.856761</td>\n",
       "      <td>0.779200</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>5.862208</td>\n",
       "      <td>0.779200</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>2.391222</td>\n",
       "      <td>0.779200</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>2.402852</td>\n",
       "      <td>0.779200</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>2.416231</td>\n",
       "      <td>0.779200</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>2.429330</td>\n",
       "      <td>0.779200</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>2.438496</td>\n",
       "      <td>0.779200</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>2.447646</td>\n",
       "      <td>0.779200</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>2.454325</td>\n",
       "      <td>0.779200</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>2.460700</td>\n",
       "      <td>0.779200</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>2.466673</td>\n",
       "      <td>0.779200</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>2.471555</td>\n",
       "      <td>0.779200</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>2.477307</td>\n",
       "      <td>0.779200</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>2.484222</td>\n",
       "      <td>0.779200</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>2.488211</td>\n",
       "      <td>0.779200</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>2.492499</td>\n",
       "      <td>0.779200</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>2.496842</td>\n",
       "      <td>0.779200</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>2.502855</td>\n",
       "      <td>0.779200</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>2.505090</td>\n",
       "      <td>0.779200</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>2.511508</td>\n",
       "      <td>0.779200</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>2.514202</td>\n",
       "      <td>0.779200</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>2.516758</td>\n",
       "      <td>0.779200</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>2.523776</td>\n",
       "      <td>0.779200</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>2.525197</td>\n",
       "      <td>0.779200</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>2.528247</td>\n",
       "      <td>0.779200</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>2.535896</td>\n",
       "      <td>0.779200</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>2.537508</td>\n",
       "      <td>0.779200</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>2.540899</td>\n",
       "      <td>0.779200</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>2.542626</td>\n",
       "      <td>0.779200</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>2.549337</td>\n",
       "      <td>0.779200</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>2.580306</td>\n",
       "      <td>0.779200</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>2.582233</td>\n",
       "      <td>0.779200</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>2.586120</td>\n",
       "      <td>0.779200</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>2.586159</td>\n",
       "      <td>0.779200</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>2.593551</td>\n",
       "      <td>0.779200</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>2.595737</td>\n",
       "      <td>0.779200</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>2.598021</td>\n",
       "      <td>0.779200</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>2.600121</td>\n",
       "      <td>0.779200</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>2.602514</td>\n",
       "      <td>0.779200</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>2.606102</td>\n",
       "      <td>0.779200</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>2.610797</td>\n",
       "      <td>0.779200</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>2.610815</td>\n",
       "      <td>0.779200</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>2.613453</td>\n",
       "      <td>0.779200</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>2.615785</td>\n",
       "      <td>0.779200</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>2.618572</td>\n",
       "      <td>0.779200</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>2.622415</td>\n",
       "      <td>0.779200</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>2.625370</td>\n",
       "      <td>0.779200</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.627834</td>\n",
       "      <td>0.779200</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>2.627848</td>\n",
       "      <td>0.779200</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>2.630986</td>\n",
       "      <td>0.779200</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>2.631000</td>\n",
       "      <td>0.779200</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>2.633620</td>\n",
       "      <td>0.779200</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.636967</td>\n",
       "      <td>0.779200</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>2.636977</td>\n",
       "      <td>0.779200</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>2.641118</td>\n",
       "      <td>0.779200</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>83</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>2.641124</td>\n",
       "      <td>0.779200</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>2.647504</td>\n",
       "      <td>0.779200</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.647508</td>\n",
       "      <td>0.779200</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>2.647512</td>\n",
       "      <td>0.779200</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.647515</td>\n",
       "      <td>0.779200</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.647514</td>\n",
       "      <td>0.779200</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>89</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.651387</td>\n",
       "      <td>0.779200</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.651385</td>\n",
       "      <td>0.779200</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>91</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>2.651379</td>\n",
       "      <td>0.779200</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.654367</td>\n",
       "      <td>0.779200</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='20' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [20/21 00:02 < 00:00, 8.68 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 24\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 24\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 24\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 24\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 24\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 24\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 24\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 24\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 24\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 24\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 24\n",
      "Saving model checkpoint to test-trainer/checkpoint-500\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 24\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 24\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 24\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 24\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 24\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 24\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 24\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 24\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 24\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 24\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 24\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 24\n",
      "Saving model checkpoint to test-trainer/checkpoint-1000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 24\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 24\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 24\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 24\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 24\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 24\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 24\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 24\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 24\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 24\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 24\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 24\n",
      "Saving model checkpoint to test-trainer/checkpoint-1500\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 24\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 24\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 24\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 24\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 24\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 24\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 24\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 24\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 24\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 24\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 24\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 24\n",
      "Saving model checkpoint to test-trainer/checkpoint-2000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 24\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 24\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 24\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 24\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 24\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 24\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 24\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 24\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 24\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 24\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 24\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 24\n",
      "Saving model checkpoint to test-trainer/checkpoint-2500\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 24\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 24\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 24\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 24\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 24\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 24\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 24\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 24\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 24\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 24\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 24\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 24\n",
      "Saving model checkpoint to test-trainer/checkpoint-3000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 24\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 24\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 24\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 24\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 24\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 24\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 24\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 24\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 24\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 24\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 24\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 24\n",
      "Saving model checkpoint to test-trainer/checkpoint-3500\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 24\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 24\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 24\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 24\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 24\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 24\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 24\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 24\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 24\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 24\n"
     ]
    }
   ],
   "source": [
    "### SUCC GPT2\n",
    "mygpt2_succ_trainer = Trainer(mygpt2_succ_model, succ_training_args,\n",
    "    train_dataset = succ_train_dataset,\n",
    "    eval_dataset = succ_test_dataset,\n",
    "    compute_metrics = succ_compute_metrics)\n",
    "mygpt2_succ_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e3abe4-9702-4d2a-80ab-e6cf6288c8e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91cc72fb-230f-4d7b-b8da-ef222ba02124",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c22439a-e5bd-4454-bbf4-21989d0cc7eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a2a08f-dc15-4d91-8800-fb7cc56b4d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch = next(iter(DataLoader(train_qed_dataset, batch_size=8)))\n",
    "# mygpt2_qed_model.cpu().eval()\n",
    "# print(f\"training? {mygpt2_qed_model.training}\")\n",
    "# out = mygpt2_qed_model(**batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4764ed18-f68b-4565-8d98-97b782b45b79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45ffccd-f33f-4b1f-b3ad-195404fedcef",
   "metadata": {},
   "outputs": [],
   "source": [
    "mytf_trainer = Trainer(\n",
    "    mytf_qed_model,\n",
    "    training_args,\n",
    "    train_dataset = train_qed_dataset,\n",
    "    eval_dataset = test_qed_dataset,\n",
    "    compute_metrics = compute_metrics)\n",
    "\n",
    "mytf_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b89dd0-50d2-4bc8-b290-e0a23d99a336",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfe58ef-b42c-4b02-b7b5-12fffda4b3ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ffe5c0-f35f-460c-acc0-6a6c84890ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "inspect.getfile(mygpt2_trainer.predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c555076-4b99-4faa-b4c3-4bb56909156b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bce_loss = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003a9d90-0923-440d-bbde-56c43fcaaf3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bce_loss(torch.rand(3,4,5), torch.rand(3,4,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0bd22e-096b-4608-a4c1-b6e4de3fc049",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
